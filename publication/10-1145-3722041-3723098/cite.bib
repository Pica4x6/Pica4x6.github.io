@inproceedings{10.1145/3722041.3723098,
 abstract = {Transformer-based models have emerged as a powerful solution for network traffic classification, achieving high accuracy by autonomously learning patterns in raw traffic data. However, their high computational costs make real-time deployment impractical. In contrast, industry-proven tools like Snort and Suricata offer efficient network analysis but rely on manually crafted signatures, resulting in slower updates and limited adaptability to emerging threats.In this work, we propose a cascading model that leverages the strengths of both approaches. During training, a transformer-based model learns traffic patterns, which are then extracted using SHAP analysis to enhance the knowledge base of a signature-based IDS. In deployment, the IDS handles routine classifications, while only complex cases are escalated to the transformer model. Our experiments combining the analysis of ET-BERT with Snort demonstrate a four-fold performance improvement over running only ET-BERT without compromising false positive or false negative rates.},
 address = {New York, NY, USA},
 author = {Changrampadi, Mohamed Hashim and Almgren, Magnus and Picazo-Sanchez, Pablo and Ali-Eldin, Ahmed},
 booktitle = {Proceedings of the 18th European Workshop on Systems Security},
 doi = {10.1145/3722041.3723098},
 isbn = {9798400715631},
 keywords = {Intrusion Detection Systems (IDS), Network Pre-trained Models, Network Traffic Analysis},
 location = {Rotterdam, Netherlands},
 numpages = {7},
 pages = {33â€“39},
 publisher = {Association for Computing Machinery},
 series = {EuroSec'25},
 title = {Snort Meets Transformers: Accelerating Transformer-Based Network Traffic Classification for Real-Time Performance},
 url = {https://doi.org/10.1145/3722041.3723098},
 year = {2025}
}

